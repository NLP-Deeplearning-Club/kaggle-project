{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM + Attention + Preprocessing\n",
    "- Based on previous LSTM + Attention Model, add some preprocessings\n",
    "    - Use only 10 labels + silence + unknown instead of all 32 labels\n",
    "    - Apply preprocessing for input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the words that we predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 possible labels : ['silence', 'unknown', 'yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n"
     ]
    }
   ],
   "source": [
    "wanted_words = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
    "possible_labels = ['silence', 'unknown'] + wanted_words\n",
    "\n",
    "print(\"{} possible labels : {}\".format(len(possible_labels), possible_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and save wav data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio\n",
    "from tensorflow.python.ops import io_ops\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.util import compat\n",
    "\n",
    "def load_wav_file_tf(filename):\n",
    "    with tf.Session(graph=tf.Graph()) as sess:\n",
    "        wav_filename_placeholder = tf.placeholder(tf.string, [])\n",
    "        wav_loader = io_ops.read_file(wav_filename_placeholder)\n",
    "        wav_decoder = contrib_audio.decode_wav(wav_loader, desired_channels=1)\n",
    "        return sess.run(\n",
    "            wav_decoder,\n",
    "            feed_dict={wav_filename_placeholder: filename}).audio.flatten()\n",
    "\n",
    "def load_wav_file(filename):\n",
    "    \"\"\"Loads an audio file and returns a float PCM-encoded array of samples.\n",
    "  \n",
    "    Args:\n",
    "        filename: Path to the .wav file to load.\n",
    "    Returns:\n",
    "        Numpy array holding the sample data as floats between -1.0 and 1.0.\n",
    "    \"\"\"\n",
    "    \n",
    "    _, wav = wavfile.read(str(filename))\n",
    "    wav = wav.astype(np.float32) / np.iinfo(np.int16).max\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a file to have a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.15555283e-05,   3.05185094e-05,   1.83111057e-04, ...,\n",
       "        -3.05185094e-05,  -9.15555283e-05,   1.22074038e-04], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "load_wav_file(os.path.join(os.getcwd(),'dataset','train','audio','bed','00176480_nohash_0.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################ Train & Val & Test Split ################\n",
    "validation_percentage = 10\n",
    "testing_percentage    = 10\n",
    "\n",
    "################ Silence and Unknown Ratio ################\n",
    "silence_percentage = 10.0\n",
    "unknown_percentage = 10.0\n",
    "\n",
    "##################### Labels #############################\n",
    "label_count = len(possible_labels)\n",
    "\n",
    "###################### Audio #############################\n",
    "sample_rate = 16000\n",
    "clip_duration_ms = 1000\n",
    "desired_samples = 16000\n",
    "\n",
    "################ Background Noise ########################\n",
    "background_volume_range = 0.1\n",
    "background_frequency = 0.1\n",
    "\n",
    "################### Wav Shifting #########################\n",
    "time_shift = int(desired_samples/8)\n",
    "\n",
    "############### MFCC Processing Params ###################\n",
    "# Duration of frequency analysis window.\n",
    "window_size_ms = 30.0\n",
    "# How far to move in time between frequency windows.\n",
    "window_stride_ms = 10.0\n",
    "# Number of frequency bins to use for analysis.\n",
    "dct_coefficient_count = 26\n",
    "\n",
    "################# Keras Model Params #####################\n",
    "max_len = 99\n",
    "embed_dim = dct_coefficient_count\n",
    "MODEL_TYPE = \"bi-lstm\"\n",
    "ATTENTION = True\n",
    "LEARN_RATE = 0.00001\n",
    "BATCH_SIZE = batch_size = 32\n",
    "INPUT_SHAPE = [max_len, embed_dim]\n",
    "EPOCHE = 4\n",
    "NUM_HIDDEN = 100\n",
    "TIME_STEPS = max_len\n",
    "SINGLE_ATTENTION_VECTOR = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train, validation and test based on its name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tell if a file is belonging to train, val or test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import re\n",
    "import hashlib\n",
    "\n",
    "from tensorflow.python.util import compat\n",
    "\n",
    "MAX_NUM_WAVS_PER_CLASS = 2 ** 27 - 1  # ~134M\n",
    "\n",
    "def which_set(filename, validation_percentage=validation_percentage, testing_percentage=testing_percentage):\n",
    "    \"\"\"Determines which data partition the file should belong to.\n",
    "      \n",
    "    Args:\n",
    "        filename: File path of the data sample.\n",
    "        validation_percentage: How much of the data set to use for validation.\n",
    "        testing_percentage: How much of the data set to use for testing.\n",
    "    Returns:\n",
    "        String, one of 'training', 'validation', or 'testing'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get hash value based on filename\n",
    "    base_name = os.path.basename(filename)\n",
    "    hash_name = re.sub(r'_nohash_.*$', '', base_name)\n",
    "    hash_name_hashed = hashlib.sha1(compat.as_bytes(hash_name)).hexdigest()\n",
    "    \n",
    "    # Turn hash value -> percentage\n",
    "    percentage_hash = int(hash_name_hashed, 16) \\\n",
    "        % (MAX_NUM_WAVS_PER_CLASS + 1) * (100.0 / MAX_NUM_WAVS_PER_CLASS)\n",
    "    \n",
    "    # Assign which data set it belongs to by hash percentage\n",
    "    if percentage_hash < validation_percentage:\n",
    "        result = 'validation'\n",
    "    elif percentage_hash < testing_percentage + validation_percentage:\n",
    "        result = 'testing'\n",
    "    else:\n",
    "        result = 'training'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give a random file name and see its belonging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "which_set(os.path.join(os.getcwd(),'dataset','train','audio','bed','00176480_nohash_0.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepares a list of the samples organized by set and label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_seed = 1234\n",
    "data_dir = os.path.join(os.getcwd(),'dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import glob\n",
    "\n",
    "def prepare_data_index():\n",
    "\n",
    "    random.seed(random_seed)\n",
    "    wanted_words_index = {}\n",
    "    for index, word in enumerate(wanted_words):\n",
    "        wanted_words_index[word] = index + 2\n",
    "\n",
    "    data_index = {'validation': [], 'testing': [],\n",
    "                           'training': []}\n",
    "    unknown_index = {'validation': [], 'testing': [],\n",
    "                         'training': []}\n",
    "    all_words = {}\n",
    "\n",
    "    # Look through all the subfolders to find audio samples\n",
    "    search_path = os.path.join(data_dir,'train','audio','*','*.wav')\n",
    "\n",
    "    for wav_path in glob.glob(search_path):\n",
    "        (_, word) = os.path.split(os.path.dirname(wav_path))\n",
    "        word = word.lower()\n",
    "        if word == '_background_noise_':\n",
    "            continue\n",
    "        all_words[word] = True\n",
    "        set_index = which_set(wav_path)\n",
    "        if word in wanted_words_index:\n",
    "            data_index[set_index].append({'label': word, 'file': wav_path})\n",
    "        else:\n",
    "            unknown_index[set_index].append({'label': word, 'file': wav_path})\n",
    "\n",
    "    # We need an arbitrary file to load as the input for the silence samples.\n",
    "    # It's multiplied by zero later, so the content doesn't matter.\n",
    "\n",
    "    silence_wav_path = data_index['training'][0]['file']\n",
    "    for set_index in ['validation', 'testing', 'training']:\n",
    "        set_size = len(data_index[set_index])\n",
    "        silence_size = int(math.ceil(set_size * silence_percentage / 100))\n",
    "        for _ in range(silence_size):\n",
    "            data_index[set_index].append({'label': 'silence',\n",
    "                    'file': silence_wav_path})\n",
    "\n",
    "        # Pick some unknowns to add to each partition of the data set.\n",
    "        random.shuffle(unknown_index[set_index])\n",
    "        unknown_size = int(math.ceil(set_size * unknown_percentage / 100))\n",
    "        data_index[set_index].extend((unknown_index[set_index])[:unknown_size])\n",
    "        \n",
    "        \n",
    "    # Make sure the ordering is random.\n",
    "    for set_index in ['validation', 'testing', 'training']:\n",
    "        random.shuffle(data_index[set_index])\n",
    "\n",
    "    # Prepare the rest of the result data structure.\n",
    "    words_list = possible_labels\n",
    "    word_to_index = {}\n",
    "    for word in all_words:\n",
    "        if word in wanted_words_index:\n",
    "            word_to_index[word] = wanted_words_index[word]\n",
    "        else:\n",
    "            word_to_index[word] = 1\n",
    "    word_to_index['silence'] = 0\n",
    "    \n",
    "    return data_index, word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'silence', 'file': '/Users/yufan/Documents/workspace/kaggle-project/dataset/train/audio/right/988e2f9a_nohash_0.wav'}\n",
      "{'label': 'right', 'file': '/Users/yufan/Documents/workspace/kaggle-project/dataset/train/audio/right/68dd409e_nohash_0.wav'}\n",
      "{'label': 'right', 'file': '/Users/yufan/Documents/workspace/kaggle-project/dataset/train/audio/right/ab7b5acd_nohash_1.wav'}\n"
     ]
    }
   ],
   "source": [
    "data_index, word_to_index = prepare_data_index()\n",
    "print(data_index['training'][0])\n",
    "print(data_index['testing'][0])\n",
    "print(data_index['validation'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 22246, Test 3081, Validation 3093.\n"
     ]
    }
   ],
   "source": [
    "print(\"Train {}, Test {}, Validation {}.\".format( \\\n",
    "    len(data_index['training']), len(data_index['testing']), len(data_index['validation'] ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right ->  7\n",
      "eight ->  1\n",
      "cat ->  1\n",
      "tree ->  1\n",
      "bed ->  1\n",
      "happy ->  1\n",
      "go ->  11\n",
      "dog ->  1\n",
      "no ->  3\n",
      "wow ->  1\n",
      "nine ->  1\n",
      "left ->  6\n",
      "stop ->  10\n",
      "three ->  1\n",
      "sheila ->  1\n",
      "one ->  1\n",
      "bird ->  1\n",
      "zero ->  1\n",
      "seven ->  1\n",
      "up ->  4\n",
      "marvin ->  1\n",
      "two ->  1\n",
      "house ->  1\n",
      "down ->  5\n",
      "six ->  1\n",
      "yes ->  2\n",
      "on ->  8\n",
      "five ->  1\n",
      "off ->  9\n",
      "four ->  1\n",
      "silence ->  0\n"
     ]
    }
   ],
   "source": [
    "for word in word_to_index:\n",
    "    print(word, '-> ', word_to_index[word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare background data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_background_data():\n",
    "\n",
    "    background_data = []\n",
    "    background_wavfiles = glob.glob(os.path.join(data_dir,'train','audio','_background_noise_','*.wav'))\n",
    "\n",
    "    for wavfile in background_wavfiles:\n",
    "        wav = load_wav_file(wavfile)\n",
    "        background_data.append(wav)\n",
    "    \n",
    "    return background_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    }
   ],
   "source": [
    "background_data = prepare_background_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background data size: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"Background data size: {}\".format(len(background_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "# Preprocessing and Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make wav same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def desired_samples_wav(wav, desired_samples=desired_samples):\n",
    "    wav_length = wav.shape[0]\n",
    "    \n",
    "    if wav_length < desired_samples:\n",
    "        # Pad 0 at the end\n",
    "        desired_wav = np.lib.pad(wav, (0, desired_samples-wav_length), mode='constant')\n",
    "    elif wav_length > desired_samples:\n",
    "        # Random choose a range from the data\n",
    "        start = np.random.randint(0, wav_length-desired_samples)\n",
    "        desired_wav = wav[start:start+desired_samples]\n",
    "    else:\n",
    "        desired_wav = wav\n",
    "        \n",
    "    return desired_wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set all silence's volumn as all zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def silence_as_zero(wav, label):\n",
    "    \n",
    "    if label == 'silence':\n",
    "        # If silence, set all volumn as 0\n",
    "        volume_scale = 0\n",
    "    else:\n",
    "        volume_scale = 1\n",
    "    \n",
    "    return np.multiply(wav, volume_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File to be processed: /Users/yufan/Documents/workspace/kaggle-project/dataset/train/audio/right/988e2f9a_nohash_0.wav Label: silence\n",
      "Before processing: [-0.00064089 -0.00091556 -0.00088504 ..., -0.0004883  -0.00054933\n",
      " -0.00085452]\n",
      "After processing: [-0. -0. -0. ..., -0. -0. -0.]\n"
     ]
    }
   ],
   "source": [
    "wav_filename = data_index['training'][0]['file']\n",
    "wav_label = data_index['training'][0]['label']\n",
    "print(\"File to be processed:\", wav_filename, 'Label:', wav_label)\n",
    "wav_data = load_wav_file(wav_filename)\n",
    "print(\"Before processing:\", wav_data)\n",
    "procssed_wav_data = silence_as_zero(wav_data, wav_label)\n",
    "print(\"After processing:\", procssed_wav_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shift the sample's start position, and pad any gaps with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shift_and_pad_zeros(wav, time_shift=time_shift):\n",
    "    \n",
    "    wav_length = wav.shape[0]\n",
    "    \n",
    "    if time_shift > 0:\n",
    "        time_shift_amount = np.random.randint(-time_shift, time_shift)\n",
    "    else:\n",
    "        time_shift_amount = 0\n",
    "    if time_shift_amount > 0:\n",
    "        shifted_wav = np.lib.pad(wav, (0, time_shift_amount), mode='constant')\n",
    "    else:\n",
    "        shifted_wav = np.lib.pad(wav, (-time_shift_amount, 0), mode='constant')\n",
    "    \n",
    "    return shifted_wav[:wav_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File to be processed: /Users/yufan/Documents/workspace/kaggle-project/dataset/train/audio/right/988e2f9a_nohash_0.wav Label: silence\n",
      "Before processing: [-0.00064089 -0.00091556 -0.00088504 ..., -0.0004883  -0.00054933\n",
      " -0.00085452]\n",
      "After processing: [-0.00064089 -0.00091556 -0.00088504 ..., -0.0004883  -0.00054933\n",
      " -0.00085452]\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "wav_filename = data_index['training'][0]['file']\n",
    "wav_label = data_index['training'][0]['label']\n",
    "print(\"File to be processed:\", wav_filename, 'Label:', wav_label)\n",
    "wav_data = load_wav_file(wav_filename)\n",
    "print(\"Before processing:\", wav_data)\n",
    "procssed_wav_data = shift_and_pad_zeros(wav_data, 3000)\n",
    "print(\"After processing:\", procssed_wav_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mix background noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    }
   ],
   "source": [
    "background_data = prepare_background_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mix_background_noise(wav, \n",
    "                         background_volume_range=background_volume_range, \n",
    "                         background_frequency=background_frequency,\n",
    "                         background_data=background_data):\n",
    "    \n",
    "    wav_length = wav.shape[0]\n",
    "    wav = wav.reshape(wav_length, 1)\n",
    "    \n",
    "    # Random choose a background data\n",
    "    background_index = np.random.randint(len(background_data))\n",
    "    background_samples = background_data[background_index]\n",
    "    \n",
    "    # Random shift the background data\n",
    "    background_offset = np.random.randint(\n",
    "        0, len(background_samples) - desired_samples)\n",
    "    background_clipped = background_samples[background_offset:(background_offset + desired_samples)]\n",
    "    background_reshaped = background_clipped.reshape([desired_samples, 1])\n",
    "    \n",
    "    # Random choose add background noise or not\n",
    "    if np.random.uniform(0, 1) < background_frequency:\n",
    "        background_volume = np.random.uniform(0, background_volume_range)\n",
    "    else:\n",
    "        background_volume = 0\n",
    "    background_noise = np.multiply(background_reshaped, background_volume)\n",
    "    wav_with_noise = background_noise + wav   \n",
    "    \n",
    "    # Clip by -1, 1\n",
    "    background_clamp = np.clip(wav_with_noise, -1.0, 1.0)\n",
    "    \n",
    "    return wav_with_noise.reshape(wav_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x134ce7240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.056215096"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(wav_data)\n",
    "plt.show()\n",
    "\n",
    "np.max(wav_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1326c6898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mix_wav = mix_background_noise(wav_data, 0.1, 0.1)\n",
    "\n",
    "plt.plot(mix_wav)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MFCC Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window_size_samples = int(sample_rate * window_size_ms / 1000)\n",
    "window_stride_samples = int(sample_rate * window_stride_ms / 1000)\n",
    "length_minus_window = desired_samples - window_size_samples\n",
    "if length_minus_window < 0:\n",
    "    spectrogram_length = 0\n",
    "else:\n",
    "    spectrogram_length = 1 + int(length_minus_window\n",
    "            / window_stride_samples)\n",
    "fingerprint_size = dct_coefficient_count * spectrogram_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import python_speech_features\n",
    "\n",
    "def mfcc(wav, sample_rate=desired_samples, **kwargs):\n",
    "    \"\"\"mfcc,python_speech_features\n",
    "\n",
    "    Parameters:\n",
    "        wav (np.ndarray): - \n",
    "        sample_rate (int): - \n",
    "        numcep (int): - ,13\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: - mfcc(),shape(times.shape,numcep)\n",
    "    \"\"\"\n",
    "    return python_speech_features.mfcc(wav, sample_rate, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 26)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc(wav_data, numcep = 26).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(fname, label, mode='train'):\n",
    "    wav = load_wav_file(fname)\n",
    "    wav = desired_samples_wav(wav)\n",
    "    if mode=='train':\n",
    "        wav = silence_as_zero(wav, label)\n",
    "        wav = shift_and_pad_zeros(wav)\n",
    "    wav = mix_background_noise(wav)\n",
    "    return mfcc(wav,numcep=dct_coefficient_count), word_to_index[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "itr = 0\n",
    "all_data_index = data_index['training'] + data_index['testing'] + data_index['validation']\n",
    "\n",
    "def all_data_generator(batch_size=batch_size):\n",
    "    \n",
    "    while 1:\n",
    "        global itr\n",
    "        if itr + batch_size >= len(all_data_index):\n",
    "            itr = 0\n",
    "\n",
    "        X_batches = []\n",
    "        Y_batches = []\n",
    "\n",
    "        for i in range(itr, itr+batch_size):\n",
    "            fname = all_data_index[i]['file']\n",
    "            label = all_data_index[i]['label']\n",
    "            X_input, Y_input = preprocess(fname, label)\n",
    "            X_batches.append(X_input)\n",
    "            Y_batches.append(Y_input)\n",
    "            \n",
    "        itr = itr + batch_size\n",
    "\n",
    "        yield np.array(X_batches), to_categorical(np.array(Y_batches).reshape(batch_size, 1), num_classes=label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_itr = 0\n",
    "train_data_index = data_index['training']\n",
    "\n",
    "def train_generator(batch_size=batch_size):\n",
    "    \n",
    "    while 1:\n",
    "        global train_itr\n",
    "        if train_itr + batch_size >= len(train_data_index):\n",
    "            train_itr = 0\n",
    "\n",
    "        X_batches = []\n",
    "        Y_batches = []\n",
    "\n",
    "        for i in range(train_itr, train_itr+batch_size):\n",
    "            fname = train_data_index[i]['file']\n",
    "            label = train_data_index[i]['label']\n",
    "            X_input, Y_input = preprocess(fname, label)\n",
    "            X_batches.append(X_input)\n",
    "            Y_batches.append(Y_input)\n",
    "            \n",
    "        train_itr = train_itr + batch_size\n",
    "\n",
    "        yield np.array(X_batches), to_categorical(np.array(Y_batches).reshape(batch_size, 1), num_classes=label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_itr = 0\n",
    "val_data_index = data_index['validation']\n",
    "\n",
    "def val_generator(batch_size=batch_size):\n",
    "    \n",
    "    while 1:\n",
    "        global val_itr\n",
    "        if val_itr + batch_size >= len(val_data_index):\n",
    "            val_itr = 0\n",
    "\n",
    "        X_batches = []\n",
    "        Y_batches = []\n",
    "\n",
    "        for i in range(val_itr, val_itr+batch_size):\n",
    "            fname = val_data_index[i]['file']\n",
    "            label = val_data_index[i]['label']\n",
    "            X_input, Y_input = preprocess(fname, label, mode='val')\n",
    "            X_batches.append(X_input)\n",
    "            Y_batches.append(Y_input)\n",
    "            \n",
    "        val_itr = val_itr + batch_size\n",
    "\n",
    "        yield np.array(X_batches), to_categorical(np.array(Y_batches).reshape(batch_size, 1), num_classes=label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_index = data_index['testing']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "# Build Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, GRU, SimpleRNN, GlobalAveragePooling1D, AveragePooling1D, Activation, Bidirectional\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.layers import merge\n",
    "from keras.layers.core import *\n",
    "from keras.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/anaconda/lib/python3.6/site-packages/Keras-2.0.8-py3.6.egg/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "def attention_3d_block(inputs):\n",
    "    # inputs.shape = (batch_size, time_steps, input_dim)\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    a = Permute((2, 1))(inputs)\n",
    "    a = Reshape((input_dim, TIME_STEPS))(a)\n",
    "    a = Dense(TIME_STEPS, activation='softmax')(a)\n",
    "    if SINGLE_ATTENTION_VECTOR:\n",
    "        a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
    "        a = RepeatVector(input_dim)(a)\n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "    output_attention_mul = merge([inputs, a_probs], name='attention_mul', mode='mul')\n",
    "    return output_attention_mul\n",
    "\n",
    "inputs = Input(shape=(INPUT_SHAPE))\n",
    "# RNN Layer\n",
    "if MODEL_TYPE == 'rnn':\n",
    "    rnn_out = SimpleRNN(NUM_HIDDEN, return_sequences=True)(inputs)\n",
    "elif MODEL_TYPE == 'gru':\n",
    "    rnn_out = GRU(NUM_HIDDEN, return_sequences=True)(inputs)\n",
    "elif MODEL_TYPE == 'lstm':\n",
    "    rnn_out = LSTM(NUM_HIDDEN, return_sequences=True)(inputs)\n",
    "elif MODEL_TYPE == 'bi-lstm':\n",
    "    rnn_out = Bidirectional(LSTM(NUM_HIDDEN, return_sequences=True))(inputs)\n",
    "else:\n",
    "    raise NameError(\"Unsupported model type\")\n",
    "# Attention Layer\n",
    "attention_mul = attention_3d_block(rnn_out)\n",
    "attention_mul = Flatten()(attention_mul)\n",
    "output = Dense(label_count, activation='softmax')(attention_mul)\n",
    "model = Model(input=[inputs], output=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 99, 26)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 99, 200)      101600      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 200, 99)      0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 200, 99)      0           permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 200, 99)      9900        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Permute)         (None, 99, 200)      0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_mul (Merge)           (None, 99, 200)      0           bidirectional_1[0][0]            \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 19800)        0           attention_mul[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 12)           237612      flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 349,112\n",
      "Trainable params: 349,112\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "888/888 [==============================] - 349s - loss: 0.9658 - acc: 0.6994   \n",
      "Epoch 2/4\n",
      "888/888 [==============================] - 284s - loss: 0.4610 - acc: 0.8586   \n",
      "Epoch 3/4\n",
      "888/888 [==============================] - 284s - loss: 0.3550 - acc: 0.8910   \n",
      "Epoch 4/4\n",
      "888/888 [==============================] - 285s - loss: 0.3002 - acc: 0.9078   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmodel.fit_generator(generator = train_generator(), \\n                    steps_per_epoch = len(train_data_index)//batch_size,\\n                    validation_data = val_generator(),\\n                    validation_steps = len(val_data_index)//batch_size,\\n                    epochs=EPOCHE)\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model on all dataset\n",
    "model.fit_generator(generator = all_data_generator(), \n",
    "                    steps_per_epoch = len(all_data_index)//batch_size,\n",
    "                    # validation_data = val_generator(),\n",
    "                    # validation_steps = len(val_data_index)//batch_size,\n",
    "                    epochs=EPOCHE)\n",
    "\n",
    "# Train model on train | test | val\n",
    "'''\n",
    "model.fit_generator(generator = train_generator(), \n",
    "                    steps_per_epoch = len(train_data_index)//batch_size,\n",
    "                    validation_data = val_generator(),\n",
    "                    validation_steps = len(val_data_index)//batch_size,\n",
    "                    epochs=EPOCHE)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See how it works on our split test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0/3081\n",
      "Step 100/3081\n",
      "Step 200/3081\n",
      "Step 300/3081\n",
      "Step 400/3081\n",
      "Step 500/3081\n",
      "Step 600/3081\n",
      "Step 700/3081\n",
      "Step 800/3081\n",
      "Step 900/3081\n",
      "Step 1000/3081\n",
      "Step 1100/3081\n",
      "Step 1200/3081\n",
      "Step 1300/3081\n",
      "Step 1400/3081\n",
      "Step 1500/3081\n",
      "Step 1600/3081\n",
      "Step 1700/3081\n",
      "Step 1800/3081\n",
      "Step 1900/3081\n",
      "Step 2000/3081\n",
      "Step 2100/3081\n",
      "Step 2200/3081\n",
      "Step 2300/3081\n",
      "Step 2400/3081\n",
      "Step 2500/3081\n",
      "Step 2600/3081\n",
      "Step 2700/3081\n",
      "Step 2800/3081\n",
      "Step 2900/3081\n",
      "Step 3000/3081\n",
      "Correct Prediction: 2452/3081\n"
     ]
    }
   ],
   "source": [
    "test_data_index = data_index['testing']\n",
    "correct_count = 0\n",
    "\n",
    "for i in range(len(test_data_index)):\n",
    "    fname = test_data_index[i]['file']\n",
    "    label = test_data_index[i]['label']\n",
    "    mfcc_, _ = preprocess(fname, label, mode='test')\n",
    "    predictions = model.predict(mfcc_[np.newaxis,:,:])\n",
    "    word = possible_labels[np.argmax( predictions[0] )]\n",
    "    if word == label:\n",
    "        correct_count = correct_count + 1\n",
    "    if i % 100 == 0:\n",
    "        print(\"Step {}/{}\".format(i, len(test_data_index)))\n",
    "        \n",
    "print('Correct Prediction: {}/{}'.format(correct_count, len(test_data_index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob    \n",
    "import pandas as pd\n",
    "\n",
    "test_files = glob.glob(os.path.join(data_dir,'test','audio','*.wav'))\n",
    "test_filenames = [os.path.basename(f) for f in test_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yufan/Documents/workspace/kaggle-project/dataset/test/audio/clip_667ea2de0.wav'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 0/158538\n",
      "Predicting 3000/158538\n",
      "Predicting 6000/158538\n",
      "Predicting 9000/158538\n",
      "Predicting 12000/158538\n",
      "Predicting 15000/158538\n",
      "Predicting 18000/158538\n",
      "Predicting 21000/158538\n",
      "Predicting 24000/158538\n",
      "Predicting 27000/158538\n",
      "Predicting 30000/158538\n",
      "Predicting 33000/158538\n",
      "Predicting 36000/158538\n",
      "Predicting 39000/158538\n",
      "Predicting 42000/158538\n",
      "Predicting 45000/158538\n",
      "Predicting 48000/158538\n",
      "Predicting 51000/158538\n",
      "Predicting 54000/158538\n",
      "Predicting 57000/158538\n",
      "Predicting 60000/158538\n",
      "Predicting 63000/158538\n",
      "Predicting 66000/158538\n",
      "Predicting 69000/158538\n",
      "Predicting 72000/158538\n",
      "Predicting 75000/158538\n",
      "Predicting 78000/158538\n",
      "Predicting 81000/158538\n",
      "Predicting 84000/158538\n",
      "Predicting 87000/158538\n",
      "Predicting 90000/158538\n",
      "Predicting 93000/158538\n",
      "Predicting 96000/158538\n",
      "Predicting 99000/158538\n",
      "Predicting 102000/158538\n",
      "Predicting 105000/158538\n",
      "Predicting 108000/158538\n",
      "Predicting 111000/158538\n",
      "Predicting 114000/158538\n",
      "Predicting 117000/158538\n",
      "Predicting 120000/158538\n",
      "Predicting 123000/158538\n",
      "Predicting 126000/158538\n",
      "Predicting 129000/158538\n",
      "Predicting 132000/158538\n",
      "Predicting 135000/158538\n",
      "Predicting 138000/158538\n",
      "Predicting 141000/158538\n",
      "Predicting 144000/158538\n",
      "Predicting 147000/158538\n",
      "Predicting 150000/158538\n",
      "Predicting 153000/158538\n",
      "Predicting 156000/158538\n",
      "Finish predicting.....\n",
      "Writing to file.....\n"
     ]
    }
   ],
   "source": [
    "num_test = len(test_files)\n",
    "submission = []\n",
    "\n",
    "for i in range(num_test):\n",
    "    wav_mfcc, _ = preprocess(test_files[i], 'yes', mode='test') # Give a random label but this 'yes' is never used\n",
    "    label = possible_labels[np.argmax( model.predict(wav_mfcc[np.newaxis,:,:]) )]\n",
    "    submission.append([test_filenames[i], label])\n",
    "    if i % 3000 == 0:\n",
    "        print(\"Predicting {}/{}\".format(i, num_test))\n",
    "        \n",
    "print(\"Finish predicting.....\")\n",
    "\n",
    "submissionDF = pd.DataFrame(submission, columns=['fname','label'])\n",
    "\n",
    "print(\"Writing to file.....\")\n",
    "submissionDF.to_csv(\"submission-bi-lstm-attention-prepropcessing-1.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clip_667ea2de0.wav</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clip_4e1d2a516.wav</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clip_4746c1f34.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clip_016404de8.wav</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clip_dcb5708d7.wav</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clip_af77b5fb6.wav</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>clip_a78b014de.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>clip_25f0146ae.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>clip_f109a09ec.wav</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>clip_160d3ee69.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>clip_f07c5d227.wav</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>clip_fb1d0cdb0.wav</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>clip_d9baf3376.wav</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>clip_761388cd6.wav</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>clip_0b0070730.wav</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>clip_0033db83b.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>clip_2c1e066c9.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>clip_542857c3e.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>clip_54a4ab635.wav</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>clip_0ee7bd486.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>clip_82509c6f5.wav</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>clip_ca40c9a3c.wav</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>clip_262464bbc.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>clip_5d5805dda.wav</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>clip_d27c6b701.wav</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>clip_1859beefc.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>clip_f81fd3144.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>clip_10ca32e2a.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>clip_68f14da2e.wav</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>clip_a6046ae7e.wav</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158508</th>\n",
       "      <td>clip_6f801eaed.wav</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158509</th>\n",
       "      <td>clip_c438e6962.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158510</th>\n",
       "      <td>clip_527621afe.wav</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158511</th>\n",
       "      <td>clip_f8b9dfcc7.wav</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158512</th>\n",
       "      <td>clip_72e4c67ea.wav</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158513</th>\n",
       "      <td>clip_01c246fd5.wav</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158514</th>\n",
       "      <td>clip_b18c3acfb.wav</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158515</th>\n",
       "      <td>clip_a314d002b.wav</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158516</th>\n",
       "      <td>clip_af435863b.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158517</th>\n",
       "      <td>clip_fe8253850.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158518</th>\n",
       "      <td>clip_ffc557cfc.wav</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158519</th>\n",
       "      <td>clip_22bf70211.wav</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158520</th>\n",
       "      <td>clip_36aaada51.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158521</th>\n",
       "      <td>clip_119bad96a.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158522</th>\n",
       "      <td>clip_6b989655b.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158523</th>\n",
       "      <td>clip_702f3eae6.wav</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158524</th>\n",
       "      <td>clip_3254d8c14.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158525</th>\n",
       "      <td>clip_21bbfc938.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158526</th>\n",
       "      <td>clip_f71a75a2d.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158527</th>\n",
       "      <td>clip_8591d7073.wav</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158528</th>\n",
       "      <td>clip_d9bf91d8d.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158529</th>\n",
       "      <td>clip_786f35d38.wav</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158530</th>\n",
       "      <td>clip_e0b72e550.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158531</th>\n",
       "      <td>clip_9341d49f2.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158532</th>\n",
       "      <td>clip_3f26932c8.wav</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158533</th>\n",
       "      <td>clip_189edd540.wav</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158534</th>\n",
       "      <td>clip_7466893f8.wav</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158535</th>\n",
       "      <td>clip_064771499.wav</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158536</th>\n",
       "      <td>clip_ffc6024a6.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158537</th>\n",
       "      <td>clip_35e726bae.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158538 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     fname    label\n",
       "0       clip_667ea2de0.wav      yes\n",
       "1       clip_4e1d2a516.wav       go\n",
       "2       clip_4746c1f34.wav  unknown\n",
       "3       clip_016404de8.wav       on\n",
       "4       clip_dcb5708d7.wav       no\n",
       "5       clip_af77b5fb6.wav       on\n",
       "6       clip_a78b014de.wav  unknown\n",
       "7       clip_25f0146ae.wav  silence\n",
       "8       clip_f109a09ec.wav     down\n",
       "9       clip_160d3ee69.wav  silence\n",
       "10      clip_f07c5d227.wav     left\n",
       "11      clip_fb1d0cdb0.wav       go\n",
       "12      clip_d9baf3376.wav    right\n",
       "13      clip_761388cd6.wav       up\n",
       "14      clip_0b0070730.wav       no\n",
       "15      clip_0033db83b.wav  unknown\n",
       "16      clip_2c1e066c9.wav  silence\n",
       "17      clip_542857c3e.wav  unknown\n",
       "18      clip_54a4ab635.wav     down\n",
       "19      clip_0ee7bd486.wav  unknown\n",
       "20      clip_82509c6f5.wav      off\n",
       "21      clip_ca40c9a3c.wav       on\n",
       "22      clip_262464bbc.wav  unknown\n",
       "23      clip_5d5805dda.wav     left\n",
       "24      clip_d27c6b701.wav       no\n",
       "25      clip_1859beefc.wav  unknown\n",
       "26      clip_f81fd3144.wav  unknown\n",
       "27      clip_10ca32e2a.wav  unknown\n",
       "28      clip_68f14da2e.wav       up\n",
       "29      clip_a6046ae7e.wav      yes\n",
       "...                    ...      ...\n",
       "158508  clip_6f801eaed.wav       go\n",
       "158509  clip_c438e6962.wav  unknown\n",
       "158510  clip_527621afe.wav       on\n",
       "158511  clip_f8b9dfcc7.wav     down\n",
       "158512  clip_72e4c67ea.wav       go\n",
       "158513  clip_01c246fd5.wav       on\n",
       "158514  clip_b18c3acfb.wav       go\n",
       "158515  clip_a314d002b.wav     down\n",
       "158516  clip_af435863b.wav  unknown\n",
       "158517  clip_fe8253850.wav  unknown\n",
       "158518  clip_ffc557cfc.wav       go\n",
       "158519  clip_22bf70211.wav    right\n",
       "158520  clip_36aaada51.wav  unknown\n",
       "158521  clip_119bad96a.wav  unknown\n",
       "158522  clip_6b989655b.wav  unknown\n",
       "158523  clip_702f3eae6.wav       no\n",
       "158524  clip_3254d8c14.wav  unknown\n",
       "158525  clip_21bbfc938.wav  unknown\n",
       "158526  clip_f71a75a2d.wav  unknown\n",
       "158527  clip_8591d7073.wav      yes\n",
       "158528  clip_d9bf91d8d.wav  unknown\n",
       "158529  clip_786f35d38.wav       go\n",
       "158530  clip_e0b72e550.wav  unknown\n",
       "158531  clip_9341d49f2.wav  silence\n",
       "158532  clip_3f26932c8.wav       up\n",
       "158533  clip_189edd540.wav      off\n",
       "158534  clip_7466893f8.wav     left\n",
       "158535  clip_064771499.wav       no\n",
       "158536  clip_ffc6024a6.wav  unknown\n",
       "158537  clip_35e726bae.wav  silence\n",
       "\n",
       "[158538 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissionDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
