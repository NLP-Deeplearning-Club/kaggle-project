{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Spectrum + CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 possible labels : ['silence', 'unknown', 'yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n"
     ]
    }
   ],
   "source": [
    "wanted_words = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
    "possible_labels = ['silence', 'unknown'] + wanted_words\n",
    "\n",
    "print(\"{} possible labels : {}\".format(len(possible_labels), possible_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################ Train & Val & Test Split ################\n",
    "validation_percentage = 10\n",
    "testing_percentage    = 10\n",
    "\n",
    "################ Silence and Unknown Ratio ################\n",
    "silence_percentage = 10.0\n",
    "unknown_percentage = 10.0\n",
    "\n",
    "##################### Labels #############################\n",
    "label_count = len(possible_labels)\n",
    "\n",
    "###################### Audio #############################\n",
    "sample_rate = 16000\n",
    "clip_duration_ms = 1000\n",
    "desired_samples = 16000\n",
    "\n",
    "################ Background Noise ########################\n",
    "background_volume_range = 0.1\n",
    "background_frequency = 0.1\n",
    "\n",
    "################### Wav Shifting #########################\n",
    "time_shift = int(desired_samples/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "\n",
    "def load_wav_file(filename):\n",
    "    \"\"\"Loads an audio file and returns a float PCM-encoded array of samples.\n",
    "  \n",
    "    Args:\n",
    "        filename: Path to the .wav file to load.\n",
    "    Returns:\n",
    "        Numpy array holding the sample data as floats between -1.0 and 1.0.\n",
    "    \"\"\"\n",
    "    \n",
    "    _, wav = wavfile.read(str(filename))\n",
    "    wav = wav.astype(np.float32) / np.iinfo(np.int16).max\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import re\n",
    "import hashlib\n",
    "\n",
    "from tensorflow.python.util import compat\n",
    "\n",
    "MAX_NUM_WAVS_PER_CLASS = 2 ** 27 - 1  # ~134M\n",
    "\n",
    "def which_set(filename, validation_percentage=validation_percentage, testing_percentage=testing_percentage):\n",
    "    \"\"\"Determines which data partition the file should belong to.\n",
    "      \n",
    "    Args:\n",
    "        filename: File path of the data sample.\n",
    "        validation_percentage: How much of the data set to use for validation.\n",
    "        testing_percentage: How much of the data set to use for testing.\n",
    "    Returns:\n",
    "        String, one of 'training', 'validation', or 'testing'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get hash value based on filename\n",
    "    base_name = os.path.basename(filename)\n",
    "    hash_name = re.sub(r'_nohash_.*$', '', base_name)\n",
    "    hash_name_hashed = hashlib.sha1(compat.as_bytes(hash_name)).hexdigest()\n",
    "    \n",
    "    # Turn hash value -> percentage\n",
    "    percentage_hash = int(hash_name_hashed, 16) \\\n",
    "        % (MAX_NUM_WAVS_PER_CLASS + 1) * (100.0 / MAX_NUM_WAVS_PER_CLASS)\n",
    "    \n",
    "    # Assign which data set it belongs to by hash percentage\n",
    "    if percentage_hash < validation_percentage:\n",
    "        result = 'validation'\n",
    "    elif percentage_hash < testing_percentage + validation_percentage:\n",
    "        result = 'testing'\n",
    "    else:\n",
    "        result = 'training'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_seed = 1234\n",
    "data_dir = os.path.join(os.getcwd(),'dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import glob\n",
    "\n",
    "def prepare_data_index():\n",
    "\n",
    "    random.seed(random_seed)\n",
    "    wanted_words_index = {}\n",
    "    for index, word in enumerate(wanted_words):\n",
    "        wanted_words_index[word] = index + 2\n",
    "\n",
    "    data_index = {'validation': [], 'testing': [],\n",
    "                           'training': []}\n",
    "    unknown_index = {'validation': [], 'testing': [],\n",
    "                         'training': []}\n",
    "    all_words = {}\n",
    "\n",
    "    # Look through all the subfolders to find audio samples\n",
    "    search_path = os.path.join(data_dir,'train','audio','*','*.wav')\n",
    "\n",
    "    for wav_path in glob.glob(search_path):\n",
    "        (_, word) = os.path.split(os.path.dirname(wav_path))\n",
    "        word = word.lower()\n",
    "        if word == '_background_noise_':\n",
    "            continue\n",
    "        all_words[word] = True\n",
    "        set_index = which_set(wav_path)\n",
    "        if word in wanted_words_index:\n",
    "            data_index[set_index].append({'label': word, 'file': wav_path})\n",
    "        else:\n",
    "            unknown_index[set_index].append({'label': word, 'file': wav_path})\n",
    "\n",
    "    # We need an arbitrary file to load as the input for the silence samples.\n",
    "    # It's multiplied by zero later, so the content doesn't matter.\n",
    "\n",
    "    silence_wav_path = data_index['training'][0]['file']\n",
    "    for set_index in ['validation', 'testing', 'training']:\n",
    "        set_size = len(data_index[set_index])\n",
    "        silence_size = int(math.ceil(set_size * silence_percentage / 100))\n",
    "        for _ in range(silence_size):\n",
    "            data_index[set_index].append({'label': 'silence',\n",
    "                    'file': silence_wav_path})\n",
    "\n",
    "        # Pick some unknowns to add to each partition of the data set.\n",
    "        random.shuffle(unknown_index[set_index])\n",
    "        unknown_size = int(math.ceil(set_size * unknown_percentage / 100))\n",
    "        data_index[set_index].extend((unknown_index[set_index])[:unknown_size])\n",
    "        \n",
    "        \n",
    "    # Make sure the ordering is random.\n",
    "    for set_index in ['validation', 'testing', 'training']:\n",
    "        random.shuffle(data_index[set_index])\n",
    "\n",
    "    # Prepare the rest of the result data structure.\n",
    "    words_list = possible_labels\n",
    "    word_to_index = {}\n",
    "    for word in all_words:\n",
    "        if word in wanted_words_index:\n",
    "            word_to_index[word] = wanted_words_index[word]\n",
    "        else:\n",
    "            word_to_index[word] = 1\n",
    "    word_to_index['silence'] = 0\n",
    "    \n",
    "    return data_index, word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'silence', 'file': '/Users/yufan/Documents/workspace/kaggle-project/dataset/train/audio/right/988e2f9a_nohash_0.wav'}\n",
      "{'label': 'right', 'file': '/Users/yufan/Documents/workspace/kaggle-project/dataset/train/audio/right/68dd409e_nohash_0.wav'}\n",
      "{'label': 'right', 'file': '/Users/yufan/Documents/workspace/kaggle-project/dataset/train/audio/right/ab7b5acd_nohash_1.wav'}\n"
     ]
    }
   ],
   "source": [
    "data_index, word_to_index = prepare_data_index()\n",
    "print(data_index['training'][0])\n",
    "print(data_index['testing'][0])\n",
    "print(data_index['validation'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_background_data():\n",
    "\n",
    "    background_data = []\n",
    "    background_wavfiles = glob.glob(os.path.join(data_dir,'train','audio','_background_noise_','*.wav'))\n",
    "\n",
    "    for wavfile in background_wavfiles:\n",
    "        wav = load_wav_file(wavfile)\n",
    "        background_data.append(wav)\n",
    "    \n",
    "    return background_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    }
   ],
   "source": [
    "background_data = prepare_background_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "def desired_samples_wav(wav, desired_samples=desired_samples):\n",
    "    wav_length = wav.shape[0]\n",
    "    \n",
    "    if wav_length < desired_samples:\n",
    "        # Pad 0 at the end\n",
    "        desired_wav = np.lib.pad(wav, (0, desired_samples-wav_length), mode='constant')\n",
    "    elif wav_length > desired_samples:\n",
    "        # Random choose a range from the data\n",
    "        start = np.random.randint(0, wav_length-desired_samples)\n",
    "        desired_wav = wav[start:start+desired_samples]\n",
    "    else:\n",
    "        desired_wav = wav\n",
    "        \n",
    "    return desired_wav\n",
    "\n",
    "def silence_as_zero(wav, label):\n",
    "    \n",
    "    if label == 'silence':\n",
    "        # If silence, set all volumn as 0\n",
    "        volume_scale = 0\n",
    "    else:\n",
    "        volume_scale = 1\n",
    "    \n",
    "    return np.multiply(wav, volume_scale)\n",
    "\n",
    "def shift_and_pad_zeros(wav, time_shift=time_shift):\n",
    "    \n",
    "    wav_length = wav.shape[0]\n",
    "    \n",
    "    if time_shift > 0:\n",
    "        time_shift_amount = np.random.randint(-time_shift, time_shift)\n",
    "    else:\n",
    "        time_shift_amount = 0\n",
    "    if time_shift_amount > 0:\n",
    "        shifted_wav = np.lib.pad(wav, (0, time_shift_amount), mode='constant')\n",
    "    else:\n",
    "        shifted_wav = np.lib.pad(wav, (-time_shift_amount, 0), mode='constant')\n",
    "    \n",
    "    return shifted_wav[:wav_length]\n",
    "\n",
    "def mix_background_noise(wav, \n",
    "                         background_volume_range=background_volume_range, \n",
    "                         background_frequency=background_frequency,\n",
    "                         background_data=background_data):\n",
    "    \n",
    "    wav_length = wav.shape[0]\n",
    "    wav = wav.reshape(wav_length, 1)\n",
    "    \n",
    "    # Random choose a background data\n",
    "    background_index = np.random.randint(len(background_data))\n",
    "    background_samples = background_data[background_index]\n",
    "    \n",
    "    # Random shift the background data\n",
    "    background_offset = np.random.randint(\n",
    "        0, len(background_samples) - desired_samples)\n",
    "    background_clipped = background_samples[background_offset:(background_offset + desired_samples)]\n",
    "    background_reshaped = background_clipped.reshape([desired_samples, 1])\n",
    "    \n",
    "    # Random choose add background noise or not\n",
    "    if np.random.uniform(0, 1) < background_frequency:\n",
    "        background_volume = np.random.uniform(0, background_volume_range)\n",
    "    else:\n",
    "        background_volume = 0\n",
    "    background_noise = np.multiply(background_reshaped, background_volume)\n",
    "    wav_with_noise = background_noise + wav   \n",
    "    \n",
    "    # Clip by -1, 1\n",
    "    background_clamp = np.clip(wav_with_noise, -1.0, 1.0)\n",
    "    \n",
    "    return wav_with_noise.reshape(wav_length)\n",
    "\n",
    "def log_specgram(audio, sample_rate, *, window='hann', window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    \"\"\"从读出的音频数据中算出对数频谱数据\n",
    "    Parameters:\n",
    "        audio (np.ndarray): - 指明音频的振幅序列\n",
    "        sample_rate (int): - 指明抽样率\n",
    "        window (str): - 指明分窗的算法,可选的详情可以看scipy.signal.get_window的文档\n",
    "        window_size (Union[pathlib.Path,str]): - 指明音频的分窗大小\n",
    "        step_size (Union[pathlib.Path,str]): - 指明步进长度\n",
    "        eps (float): - 指明频谱强度取对数时的最小值,防止输入为0后得到负无穷\n",
    "    Returns:\n",
    "        tuple[np.ndarray,np.ndarray,np.ndarray]: - 由频率(一维),分段时间(一维)和频谱强度(二维)\\\n",
    "        组成的元组,shape(times.shape,freqs.shape)\n",
    "    \"\"\"\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                            fs=sample_rate,\n",
    "                                            window=window,\n",
    "                                            nperseg=nperseg,\n",
    "                                            noverlap=noverlap,\n",
    "                                            detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(fname, label, mode='train'):\n",
    "    wav = load_wav_file(fname)\n",
    "    wav = desired_samples_wav(wav)\n",
    "    if mode=='train':\n",
    "        wav = silence_as_zero(wav, label)\n",
    "        wav = shift_and_pad_zeros(wav)\n",
    "        wav = mix_background_noise(wav)\n",
    "    _, _, log_spec = log_specgram(wav, desired_samples)\n",
    "    return log_spec, word_to_index[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 161)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(data_index['training'][0]['file'], data_index['training'][0]['label'])[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import six\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    Input,\n",
    "    Activation,\n",
    "    Dense,\n",
    "    Flatten\n",
    ")\n",
    "from keras.layers.convolutional import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    AveragePooling2D\n",
    ")\n",
    "from keras.layers.merge import add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def _bn_relu(input):\n",
    "    \"\"\"Helper to build a BN -> relu block\n",
    "    \"\"\"\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
    "    return Activation(\"relu\")(norm)\n",
    "\n",
    "\n",
    "def _conv_bn_relu(**conv_params):\n",
    "    \"\"\"Helper to build a conv -> BN -> relu block\n",
    "    \"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, padding=padding,\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "                      kernel_regularizer=kernel_regularizer)(input)\n",
    "        return _bn_relu(conv)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _bn_relu_conv(**conv_params):\n",
    "    \"\"\"Helper to build a BN -> relu -> conv block.\n",
    "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        return Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, padding=padding,\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "                      kernel_regularizer=kernel_regularizer)(activation)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _shortcut(input, residual):\n",
    "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
    "    \"\"\"\n",
    "    # Expand channels of shortcut to match residual.\n",
    "    # Stride appropriately to match residual (width, height)\n",
    "    # Should be int if network architecture is correctly configured.\n",
    "    input_shape = K.int_shape(input)\n",
    "    residual_shape = K.int_shape(residual)\n",
    "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
    "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
    "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "    # 1 X 1 conv if shape is different. Else identity.\n",
    "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
    "        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n",
    "                          kernel_size=(1, 1),\n",
    "                          strides=(stride_width, stride_height),\n",
    "                          padding=\"valid\",\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=l2(0.0001))(input)\n",
    "\n",
    "    return add([shortcut, residual])\n",
    "\n",
    "\n",
    "def _residual_block(block_function, filters, repetitions, is_first_layer=False):\n",
    "    \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "        for i in range(repetitions):\n",
    "            init_strides = (1, 1)\n",
    "            if i == 0 and not is_first_layer:\n",
    "                init_strides = (2, 2)\n",
    "            input = block_function(filters=filters, init_strides=init_strides,\n",
    "                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
    "        return input\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n",
    "                           strides=init_strides,\n",
    "                           padding=\"same\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=l2(1e-4))(input)\n",
    "        else:\n",
    "            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3),\n",
    "                                  strides=init_strides)(input)\n",
    "\n",
    "        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def bottleneck(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    Returns:\n",
    "        A final conv layer of filters * 4\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1),\n",
    "                              strides=init_strides,\n",
    "                              padding=\"same\",\n",
    "                              kernel_initializer=\"he_normal\",\n",
    "                              kernel_regularizer=l2(1e-4))(input)\n",
    "        else:\n",
    "            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1),\n",
    "                                     strides=init_strides)(input)\n",
    "\n",
    "        conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n",
    "        residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _handle_dim_ordering():\n",
    "    global ROW_AXIS\n",
    "    global COL_AXIS\n",
    "    global CHANNEL_AXIS\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        ROW_AXIS = 1\n",
    "        COL_AXIS = 2\n",
    "        CHANNEL_AXIS = 3\n",
    "    else:\n",
    "        CHANNEL_AXIS = 1\n",
    "        ROW_AXIS = 2\n",
    "        COL_AXIS = 3\n",
    "\n",
    "\n",
    "def _get_block(identifier):\n",
    "    if isinstance(identifier, six.string_types):\n",
    "        res = globals().get(identifier)\n",
    "        if not res:\n",
    "            raise ValueError('Invalid {}'.format(identifier))\n",
    "        return res\n",
    "    return identifier\n",
    "\n",
    "\n",
    "class ResnetBuilder(object):\n",
    "    @staticmethod\n",
    "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
    "        \"\"\"Builds a custom ResNet like architecture.\n",
    "        Args:\n",
    "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
    "            num_outputs: The number of outputs at final softmax layer\n",
    "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n",
    "                The original paper used basic_block for layers < 50\n",
    "            repetitions: Number of repetitions of various block units.\n",
    "                At each block unit, the number of filters are doubled and the input size is halved\n",
    "        Returns:\n",
    "            The keras `Model`.\n",
    "        \"\"\"\n",
    "        _handle_dim_ordering()\n",
    "        if len(input_shape) != 3:\n",
    "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
    "\n",
    "        # Permute dimension order if necessary\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "            input_shape = (input_shape[1], input_shape[2], input_shape[0])\n",
    "\n",
    "        # Load function from str if needed.\n",
    "        block_fn = _get_block(block_fn)\n",
    "\n",
    "        input = Input(shape=input_shape)\n",
    "        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(input)\n",
    "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
    "\n",
    "        block = pool1\n",
    "        filters = 64\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
    "            filters *= 2\n",
    "\n",
    "        # Last activation\n",
    "        block = _bn_relu(block)\n",
    "\n",
    "        # Classifier block\n",
    "        block_shape = K.int_shape(block)\n",
    "        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n",
    "                                 strides=(1, 1))(block)\n",
    "        flatten1 = Flatten()(pool2)\n",
    "        dense = Dense(units=num_outputs, kernel_initializer=\"he_normal\",\n",
    "                      activation=\"softmax\")(flatten1)\n",
    "\n",
    "        model = Model(inputs=input, outputs=dense)\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_18(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_34(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_50(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_101(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_152(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ResnetBuilder.build_resnet_18((1,99,161), (12))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 99, 161, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 50, 81, 64)   3200        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 50, 81, 64)   256         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 50, 81, 64)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 25, 41, 64)   0           activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 25, 41, 64)   36928       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 25, 41, 64)   256         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 25, 41, 64)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 25, 41, 64)   36928       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 25, 41, 64)   0           max_pooling2d_4[0][0]            \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 25, 41, 64)   256         add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 25, 41, 64)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 25, 41, 64)   36928       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 25, 41, 64)   256         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 25, 41, 64)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 25, 41, 64)   36928       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 25, 41, 64)   0           add_25[0][0]                     \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 25, 41, 64)   256         add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 25, 41, 64)   0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 13, 21, 128)  73856       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 13, 21, 128)  512         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 13, 21, 128)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 13, 21, 128)  8320        add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 13, 21, 128)  147584      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 13, 21, 128)  0           conv2d_68[0][0]                  \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 13, 21, 128)  512         add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 13, 21, 128)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 13, 21, 128)  147584      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 13, 21, 128)  512         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 13, 21, 128)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 13, 21, 128)  147584      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 13, 21, 128)  0           add_27[0][0]                     \n",
      "                                                                 conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 13, 21, 128)  512         add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 13, 21, 128)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 7, 11, 256)   295168      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 7, 11, 256)   1024        conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 7, 11, 256)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 7, 11, 256)   33024       add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 7, 11, 256)   590080      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 7, 11, 256)   0           conv2d_73[0][0]                  \n",
      "                                                                 conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 7, 11, 256)   1024        add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 7, 11, 256)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 7, 11, 256)   590080      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 7, 11, 256)   1024        conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 7, 11, 256)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 7, 11, 256)   590080      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 7, 11, 256)   0           add_29[0][0]                     \n",
      "                                                                 conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 7, 11, 256)   1024        add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 7, 11, 256)   0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 4, 6, 512)    1180160     activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 4, 6, 512)    2048        conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 4, 6, 512)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 4, 6, 512)    131584      add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 4, 6, 512)    2359808     activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 4, 6, 512)    0           conv2d_78[0][0]                  \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 4, 6, 512)    2048        add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 4, 6, 512)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 4, 6, 512)    2359808     activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 4, 6, 512)    2048        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 4, 6, 512)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 4, 6, 512)    2359808     activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 4, 6, 512)    0           add_31[0][0]                     \n",
      "                                                                 conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 4, 6, 512)    2048        add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 4, 6, 512)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 1, 1, 512)    0           activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 512)          0           average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 12)           6156        flatten_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 11,187,212\n",
      "Trainable params: 11,179,404\n",
      "Non-trainable params: 7,808\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_data_index = data_index['training']\n",
    "batch_size=32\n",
    "\n",
    "def train_generator(batch_size=batch_size):\n",
    "    \n",
    "    while 1:\n",
    "\n",
    "        X_batches = []\n",
    "        Y_batches = []\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "            i = np.random.randint(0, len(train_data_index))\n",
    "            fname = train_data_index[i]['file']\n",
    "            label = train_data_index[i]['label']\n",
    "            X_input, Y_input = preprocess(fname, label)\n",
    "            X_input = X_input[:,:,np.newaxis]\n",
    "            X_batches.append(X_input)\n",
    "            Y_batches.append(Y_input)\n",
    "\n",
    "        yield np.array(X_batches), to_categorical(np.array(Y_batches).reshape(batch_size, 1), num_classes=label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_itr = 0\n",
    "val_data_index = data_index['validation']\n",
    "\n",
    "def val_generator(batch_size=batch_size):\n",
    "    \n",
    "    while 1:\n",
    "        global val_itr\n",
    "        if val_itr + batch_size >= len(val_data_index):\n",
    "            val_itr = 0\n",
    "\n",
    "        X_batches = []\n",
    "        Y_batches = []\n",
    "\n",
    "        for i in range(val_itr, val_itr+batch_size):\n",
    "            fname = val_data_index[i]['file']\n",
    "            label = val_data_index[i]['label']\n",
    "            X_input, Y_input = preprocess(fname, label, mode='val')\n",
    "            X_input = X_input[:,:,np.newaxis]\n",
    "            X_batches.append(X_input)\n",
    "            Y_batches.append(Y_input)\n",
    "            \n",
    "        val_itr = val_itr + batch_size\n",
    "\n",
    "        yield np.array(X_batches), to_categorical(np.array(Y_batches).reshape(batch_size, 1), num_classes=label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "160/200 [=======================>......] - ETA: 220s - loss: 2.4339 - acc: 0.4025"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator = train_generator(), \n",
    "                    steps_per_epoch = 200,\n",
    "                    validation_data = val_generator(),\n",
    "                    validation_steps = len(val_data_index)//batch_size,\n",
    "                    epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
